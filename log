工欲善其事，必先利其器

1. 给大家推荐一款mac上编写python的IDE - Pycharm， 目前我发现它的优点有：1. python intepreter 的版本控制做的很棒，可以随意切换python 版本，另外对每个版本下都安装了什么lib也一目了然。2. 对于不同版本的python，可以很简单的对其进行lib的增加和删除。减少了安装需要考虑路径等不必要的麻烦。3. 支持 自动填充 你打出一个function的开头它给你结尾这样

2.  遇到的第一个问题：
	DEBUG: Forbidden by robots.txt: 
	这是因为百度的网站的robits.txt禁止我们的爬虫访问他的任何链接。什么是robots.txt. http://www.robotstxt.org/robotstxt.html 简单来说就是对网上的爬虫的行为的一种规范，当一个爬虫来爬虫该网站时候，他会先去搜寻robots.txt然后根据里面的规则来进行爬取。
	解决方法：在settings.py中 将ROBOTSTXT_OBEY 改为False. 

	遇到的第二个问题：
	Content Security Policy: 页面设置阻止读取位于 self 的一项资源("script-src https://www.zhihu.com https://*.zhihu.com https://unpkg.zhimg.com https://unicom.zhimg.com https://*.google-analytics.com https://res.wx.qq.com 'unsafe-eval'")。 Source: onchange attribute on DIV element.
	https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP
	简单来说就是在网页中植入CSP来作为一种额外的安全措施。它可以用来减少或者阻止xss等的攻击。xss就是脚本注入。我们这里遇到的问题是 只允许来自同源的（site's own origin），但是我们的inspect element不是它本身，所以不能被解读。

	遇到的第三个问题：
	同一个post request 但是得到的response是不一样的，这样如果我们post这个request只能得到前N个问题。但是网站里面的XHR的这个request都是一样的。也就是说，它的这个request能得到不一样的response。

	遇到的第四个问题：
	爬取知乎需要进行登陆，记录登录状态是通过cooies来实现的，什么是cookies？我们如何运用它？

	解决方法： 根据分析它的登录界面发现，它有一个_xsrf value对于每次的最开始的请求是不一样的，所以首先将这个value拿出来，然后使用post进行模拟登陆试试。

	遇到的第四个问题：
	当过想讲爬去的itemdata写入json文件的时候我们发现，中文字符都是unicode，所以使用codecs lib进行打开文件。

3. 如果对某个页面进行最初始的分析？
	建议使用Firefox，下载插件firebug。 打开firebug，打开 网络-> XHR (XMLHttpRequest: API用来通过 http 游览器与webserver之间的传递)。刷新页面你就能看到从你刷新之后到页面加载完成之间的数据传递是怎么样。 再介绍一个工具 Postman，使用postman可以对这个页面的单个请求进行请求。比如 请求一个get 或者post。







计划：
1. 爬取知乎某个话题的所有问题，对于所有问题的高票回答的用户的标签都是是什么。
1.1 增加user agent, 对于每个request，随机选取一个user agent 
1.2 爬取 对某个话题第一次请求结果的数据
1.3 确定抓取的信息，定义item

抓取 问题提问者何 回答投票数前几的人 分析

