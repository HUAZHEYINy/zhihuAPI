工欲善其事，必先利其器

1. 给大家推荐一款mac上编写python的IDE - Pycharm， 目前我发现它的优点有：1. python intepreter 的版本控制做的很棒，可以随意切换python 版本，另外对每个版本下都安装了什么lib也一目了然。2. 对于不同版本的python，可以很简单的对其进行lib的增加和删除。减少了安装需要考虑路径等不必要的麻烦。3. 支持 自动填充 你打出一个function的开头它给你结尾这样

2.  遇到的第一个问题：
	DEBUG: Forbidden by robots.txt: 
	这是因为百度的网站的robits.txt禁止我们的爬虫访问他的任何链接。什么是robots.txt. http://www.robotstxt.org/robotstxt.html 简单来说就是对网上的爬虫的行为的一种规范，当一个爬虫来爬虫该网站时候，他会先去搜寻robots.txt然后根据里面的规则来进行爬取。
	解决方法：在settings.py中 将ROBOTSTXT_OBEY 改为False. 

	遇到的第二个问题：
	Content Security Policy: 页面设置阻止读取位于 self 的一项资源("script-src https://www.zhihu.com https://*.zhihu.com https://unpkg.zhimg.com https://unicom.zhimg.com https://*.google-analytics.com https://res.wx.qq.com 'unsafe-eval'")。 Source: onchange attribute on DIV element.
	https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP
	简单来说就是在网页中植入CSP来作为一种额外的安全措施。它可以用来减少或者阻止xss等的攻击。xss就是脚本注入。我们这里遇到的问题是 只允许来自同源的（site's own origin），但是我们的inspect element不是它本身，所以不能被解读。

3. 如果对某个页面进行最初始的分析？
	建议使用Firefox，下载插件firebug。 打开firebug，打开 网络-> XHR (XMLHttpRequest: API用来通过 http 游览器与webserver之间的传递)。刷新页面你就能看到从你刷新之后到页面加载完成之间的数据传递是怎么样。 再介绍一个工具 Postman，使用postman可以对这个页面的单个请求进行请求。比如 请求一个get 或者post。







计划：
1. 爬取知乎某个话题的所有问题，对于所有问题的高票回答的用户的标签都是是什么。
1.1 增加user agent, 对于每个request，随机选取一个user agent 
1.2 爬取 对某个话题第一次请求结果的数据
1.3 确定抓取的信息，定义item
1.4
